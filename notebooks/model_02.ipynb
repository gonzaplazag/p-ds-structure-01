{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing\timport OneHotEncoder\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "load_dotenv()\n",
    "os.chdir(os.getenv(\"ROOT_DIR\"))\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PARAMS --- #\n",
    "prep_id = 'prep_02'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 5) (712, 1) (179, 5) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- LOAD --- #\n",
    "x_train, y_train, x_test, y_test = utils.get_prep_df(prep_id)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "### DECISION-TREE-GDOC\n",
    "### sklearn.tree.DecisionTreeClassifier\n",
    "### sklearn v.1.3.2.\n",
    "############################################\n",
    "\n",
    "### Main ref ----------------------------------------------------------------\n",
    "# - https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "\n",
    "### Main def --------------------------------\n",
    "# Decision Trees (DTs) are a non-parametric supervised learning method \n",
    "# used for classification and regression. The goal is to create a model \n",
    "# that predicts the value of a target variable by learning simple decision \n",
    "# rules inferred from the data features. A tree can be seen as a \n",
    "# piecewise constant approximation.\n",
    "\n",
    "### Main advantages --------------------------------\n",
    "# - Simple to understand and to interpret. Trees can be visualized. White box model.\n",
    "# - Fast: The cost of using the tree (i.e., predicting data) is logarithmic \n",
    "# in the number of data points used to train the tree.\n",
    "\n",
    "### Main disadvantages --------------------------------\n",
    "# - Decision-tree learners can create over-complex trees that do not \n",
    "# generalize the data well (overfitting).\n",
    "# - Decision trees can be unstable because small variations in the \n",
    "# data might result in a completely different tree being generated. \n",
    "# This problem is mitigated by using decision trees within an ensemble.\n",
    "# - The problem of learning an optimal decision tree is known to be NP-complete \n",
    "# under several aspects of optimality and even for simple concepts. \n",
    "# Consequently, practical decision-tree learning algorithms are based on \n",
    "# heuristic algorithms such as the greedy algorithm where locally optimal \n",
    "# decisions are made at each node. Such algorithms cannot guarantee to \n",
    "# return the globally optimal decision tree. This can be mitigated by \n",
    "# training multiple trees in an ensemble learner, where the features \n",
    "# and samples are randomly sampled with replacement.\n",
    "# - Decision tree learners create biased trees if some classes dominate. \n",
    "# It is therefore recommended to BALANCE the dataset prior \n",
    "# to fitting with the decision tree.\n",
    "\n",
    "### Implementation Highlights -------------------------------------------------\n",
    "# - DecisionTreeClassifier is a class capable of performing multi-class \n",
    "# classification on a dataset\n",
    "# - the scikit-learn implementation does not support categorical variables.\n",
    "\n",
    "### Signature ----------------------------------------------------------------\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "#DecisionTreeClassifier(\n",
    "# criterion='gini', # metric to define que quality of a split.\n",
    "# splitter='best', # The best possible split is used or we use a random split?\n",
    "# max_depth=None, #!key to control overfitting\n",
    "# min_samples_split=2, \n",
    "# min_samples_leaf=1, #!key to create asymmetric trees. \n",
    "# min_weight_fraction_leaf=0.0, \n",
    "# max_features=None, # how many features consider when lookint for the best split. See doc.\n",
    "# random_state=None, \n",
    "# max_leaf_nodes=None, \n",
    "# min_impurity_decrease=0.0, \n",
    "# class_weight=None, #!  dict, list of dict or “balanced”, default=None\n",
    "# ccp_alpha=0.0\n",
    "#)\n",
    "\n",
    "#DecisionTreeClassifier(\n",
    "# criterion='gini',\n",
    "# splitter='best', \n",
    "# max_depth=None, \n",
    "# min_samples_split=2, \n",
    "# min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.0, \n",
    "# max_features=None, \n",
    "# random_state=None, \n",
    "# max_leaf_nodes=None, \n",
    "# min_impurity_decrease=0.0, \n",
    "# class_weight=None, \n",
    "# ccp_alpha=0.0\n",
    "#)\n",
    "\n",
    "### Hyperparams Comments  --------------------------------\n",
    "# - The max_depth hyperparameter controls the overall complexity of the tree. \n",
    "# This parameter is adequate under the assumption that a tree is built symmetrically. \n",
    "# However, there is no reason why a tree should be symmetrical. Indeed, optimal generalization \n",
    "# performance could be reached by growing some of the branches deeper than some others.\n",
    "\n",
    "# The hyperparameters min_samples_leaf, min_samples_split, \n",
    "# max_leaf_nodes, or min_impurity_decrease allow growing asymmetric trees and apply \n",
    "# a constraint at the leaves or nodes level. \n",
    "# ref. https://inria.github.io/scikit-learn-mooc/python_scripts/trees_hyperparameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-15 17:16:27,888] A new study created in memory with name: no-name-5e407ade-8a69-4948-8862-ded43946a661\n",
      "/tmp/ipykernel_1137969/1392542347.py:47: ExperimentalWarning: set_metric_names is experimental (supported from v3.2.0). The interface can change in the future.\n",
      "  study.set_metric_names([\"accuracy\"])\n",
      "[I 2024-10-15 17:16:28,025] Trial 1 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,056] Trial 6 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 23}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,098] Trial 2 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,134] Trial 7 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 10, 'min_samples_split': 24, 'min_samples_leaf': 12}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,181] Trial 3 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 28}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,198] Trial 11 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 20}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,215] Trial 5 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 6, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,288] Trial 10 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 16}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,315] Trial 4 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 6, 'min_samples_split': 24, 'min_samples_leaf': 21}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,322] Trial 8 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 21, 'min_samples_leaf': 15}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,346] Trial 0 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,379] Trial 12 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 6, 'min_samples_split': 22, 'min_samples_leaf': 20}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,387] Trial 15 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,435] Trial 13 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 6, 'min_samples_split': 22, 'min_samples_leaf': 14}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,461] Trial 19 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,472] Trial 14 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 27, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,505] Trial 17 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 28, 'min_samples_leaf': 22}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,518] Trial 9 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 27, 'min_samples_leaf': 16}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,537] Trial 16 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,556] Trial 18 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 28, 'min_samples_leaf': 15}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,685] Trial 20 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 2, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,693] Trial 21 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 2, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,847] Trial 22 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,875] Trial 23 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 2, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,902] Trial 27 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,932] Trial 24 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,974] Trial 25 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 2, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:28,997] Trial 28 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 2, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,004] Trial 26 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 2, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,142] Trial 29 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 12, 'min_samples_leaf': 28}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,167] Trial 30 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 28}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,234] Trial 31 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 28}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,296] Trial 33 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,404] Trial 32 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,491] Trial 34 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,546] Trial 35 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,612] Trial 36 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,758] Trial 37 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,846] Trial 39 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,879] Trial 44 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,918] Trial 38 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:29,932] Trial 40 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,032] Trial 46 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,037] Trial 41 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,124] Trial 45 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,236] Trial 43 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,241] Trial 42 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 24}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,244] Trial 47 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,249] Trial 48 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,347] Trial 49 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 24}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,427] Trial 50 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,499] Trial 52 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,568] Trial 54 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,625] Trial 56 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 8, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,728] Trial 51 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 24}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,767] Trial 53 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 18}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,846] Trial 55 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,929] Trial 57 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 7, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:30,983] Trial 63 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 17, 'min_samples_leaf': 29}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,049] Trial 60 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 15, 'min_samples_leaf': 18}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,089] Trial 59 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 8, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,096] Trial 58 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 8, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,138] Trial 61 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 16, 'min_samples_leaf': 18}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,249] Trial 65 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,259] Trial 64 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 17, 'min_samples_leaf': 18}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,280] Trial 62 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 15, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,299] Trial 67 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,407] Trial 66 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,520] Trial 68 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 31}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,603] Trial 71 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,617] Trial 69 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 19}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,770] Trial 70 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 31}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,817] Trial 72 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 31}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,821] Trial 73 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:31,979] Trial 76 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,096] Trial 75 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,126] Trial 74 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,169] Trial 81 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,191] Trial 79 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,195] Trial 77 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,246] Trial 80 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 12}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,262] Trial 78 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,354] Trial 82 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,425] Trial 83 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,500] Trial 84 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,527] Trial 86 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,629] Trial 85 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,668] Trial 87 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,819] Trial 89 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,876] Trial 88 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:32,956] Trial 93 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:33,023] Trial 90 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 12}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:33,041] Trial 97 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:33,044] Trial 91 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:33,093] Trial 95 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:33,125] Trial 98 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 28}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:33,175] Trial 96 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:33,204] Trial 92 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:33,209] Trial 94 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-15 17:16:33,210] Trial 99 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.7865534399413775.\n"
     ]
    }
   ],
   "source": [
    "# --- TUNNING ---\n",
    "# --- Objective function: define the optimization metrics ---\n",
    "# (where, for what model, what metric)\n",
    "\n",
    "def objective(trial, x, y):\n",
    "\t\n",
    "\t\t\t\t# define search space\n",
    "\t\t\t\tparams = {\n",
    "\t\t\t\t\t\t\t\t'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "\t\t\t\t\t\t\t\t'splitter': trial.suggest_categorical('splitter', ['best', 'random']),\n",
    "\t\t\t\t\t\t\t\t'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "\t\t\t\t\t\t\t\t'min_samples_split': trial.suggest_int('min_samples_split', 2, 32),\n",
    "\t\t\t\t\t\t\t\t'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 32),\n",
    "\t\t\t\t\t\t\t\t'random_state': 0\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t\t# define model\n",
    "\t\t\t\tclf\t= DecisionTreeClassifier(**params)\n",
    "\n",
    "\t\t\t\t# Eval strategy\n",
    "\t\t\t\t# It gives me the list of k scores from cv\n",
    "\t\t\t\tcv_scores = cross_val_score(clf, x, y, cv=3, scoring='accuracy')\n",
    "\n",
    "\t\t\t\tobj = cv_scores.mean()\n",
    "\t\t\t\t\n",
    "\t\t\t\t# return score for each trial\n",
    "\t\t\t\treturn obj\n",
    "\n",
    "w_func = lambda trial: objective(trial, x=x_train, y=y_train) # just a wrapper\tto pass x and y\n",
    "\n",
    "# --- study: define searching strategy (How) ---\n",
    "\n",
    "# sampler=TPESampler(): Optuna uses the Tree-structured Parzen Estimator (TPE) \n",
    "# sampler, which is a Bayesian optimization method that efficiently searches \n",
    "# through the hyperparameter space.\n",
    "\n",
    "# pruner=MedianPruner(): Optuna can prune unpromising trials early, based on the median \n",
    "# value of intermediate results. This speeds up the optimization process by discarding \n",
    "# poor-performing hyperparameter combinations early.\n",
    "\n",
    "study=optuna.create_study(\n",
    "\tsampler= optuna.samplers.TPESampler(),\n",
    "\tpruner=optuna.pruners.MedianPruner(),\n",
    "\tdirection='maximize'\n",
    "\t)\n",
    "\n",
    "study.set_metric_names([\"accuracy\"])\n",
    "\n",
    "\n",
    "# -- Start optimizing ---\n",
    "study.optimize(\n",
    "\tfunc=w_func, \n",
    "\tn_trials=100,\n",
    "\ttimeout=None, # max time in seconds\n",
    "\tn_jobs=-1 # max job  in parallel. -1 = all cpus\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in artifacts/model_02/tunning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_params': {'criterion': 'entropy',\n",
       "  'splitter': 'best',\n",
       "  'max_depth': 1,\n",
       "  'min_samples_split': 4,\n",
       "  'min_samples_leaf': 6},\n",
       " 'best_value': 0.7865534399413775,\n",
       " 'metric_names': ['accuracy']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save tunning results\n",
    "utils.tunning_results(study, os.getenv(\"ARTIFACTS_PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: artifacts/model_02/model/model.pkl\n",
      "Timestamp: 2024-10-15 17:16:51\n"
     ]
    }
   ],
   "source": [
    "# --- TRAIN ---\n",
    "x_full = pd.concat([x_train, x_test])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "best_params = study.best_params\n",
    "clf = DecisionTreeClassifier(**best_params)\n",
    "model = clf.fit(x_full, y_full)\n",
    "\n",
    "# --- save as pickle ---\n",
    "artifact_path = os.path.join(os.getenv(\"ARTIFACTS_PATH\"), utils.get_nb_name(), 'model')\n",
    "os.makedirs(artifact_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(artifact_path, 'model.pkl'), 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"Model saved at: {os.path.join(artifact_path, 'model.pkl')}\")\n",
    "print(f'Timestamp: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
