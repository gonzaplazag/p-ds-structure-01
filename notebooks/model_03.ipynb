{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing\timport OneHotEncoder\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "load_dotenv()\n",
    "os.chdir(os.getenv(\"ROOT_DIR\"))\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PARAMS --- #\n",
    "prep_id = 'prep_03'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 6) (712, 1) (179, 6) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- LOAD --- #\n",
    "x_train, y_train, x_test, y_test = utils.get_prep_df(prep_id)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "### DECISION-TREE-GDOC\n",
    "### sklearn.tree.DecisionTreeClassifier\n",
    "### sklearn v.1.3.2.\n",
    "############################################\n",
    "\n",
    "### Main ref ----------------------------------------------------------------\n",
    "# - https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "\n",
    "### Main def --------------------------------\n",
    "# Decision Trees (DTs) are a non-parametric supervised learning method \n",
    "# used for classification and regression. The goal is to create a model \n",
    "# that predicts the value of a target variable by learning simple decision \n",
    "# rules inferred from the data features. A tree can be seen as a \n",
    "# piecewise constant approximation.\n",
    "\n",
    "### Main advantages --------------------------------\n",
    "# - Simple to understand and to interpret. Trees can be visualized. White box model.\n",
    "# - Fast: The cost of using the tree (i.e., predicting data) is logarithmic \n",
    "# in the number of data points used to train the tree.\n",
    "\n",
    "### Main disadvantages --------------------------------\n",
    "# - Decision-tree learners can create over-complex trees that do not \n",
    "# generalize the data well (overfitting).\n",
    "# - Decision trees can be unstable because small variations in the \n",
    "# data might result in a completely different tree being generated. \n",
    "# This problem is mitigated by using decision trees within an ensemble.\n",
    "# - The problem of learning an optimal decision tree is known to be NP-complete \n",
    "# under several aspects of optimality and even for simple concepts. \n",
    "# Consequently, practical decision-tree learning algorithms are based on \n",
    "# heuristic algorithms such as the greedy algorithm where locally optimal \n",
    "# decisions are made at each node. Such algorithms cannot guarantee to \n",
    "# return the globally optimal decision tree. This can be mitigated by \n",
    "# training multiple trees in an ensemble learner, where the features \n",
    "# and samples are randomly sampled with replacement.\n",
    "# - Decision tree learners create biased trees if some classes dominate. \n",
    "# It is therefore recommended to BALANCE the dataset prior \n",
    "# to fitting with the decision tree.\n",
    "\n",
    "### Implementation Highlights -------------------------------------------------\n",
    "# - DecisionTreeClassifier is a class capable of performing multi-class \n",
    "# classification on a dataset\n",
    "# - the scikit-learn implementation does not support categorical variables.\n",
    "\n",
    "### Signature ----------------------------------------------------------------\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "#DecisionTreeClassifier(\n",
    "# criterion='gini', # metric to define que quality of a split.\n",
    "# splitter='best', # The best possible split is used or we use a random split?\n",
    "# max_depth=None, #!key to control overfitting\n",
    "# min_samples_split=2, \n",
    "# min_samples_leaf=1, #!key to create asymmetric trees. \n",
    "# min_weight_fraction_leaf=0.0, \n",
    "# max_features=None, # how many features consider when lookint for the best split. See doc.\n",
    "# random_state=None, \n",
    "# max_leaf_nodes=None, \n",
    "# min_impurity_decrease=0.0, \n",
    "# class_weight=None, #!  dict, list of dict or “balanced”, default=None\n",
    "# ccp_alpha=0.0\n",
    "#)\n",
    "\n",
    "#DecisionTreeClassifier(\n",
    "# criterion='gini',\n",
    "# splitter='best', \n",
    "# max_depth=None, \n",
    "# min_samples_split=2, \n",
    "# min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.0, \n",
    "# max_features=None, \n",
    "# random_state=None, \n",
    "# max_leaf_nodes=None, \n",
    "# min_impurity_decrease=0.0, \n",
    "# class_weight=None, \n",
    "# ccp_alpha=0.0\n",
    "#)\n",
    "\n",
    "### Hyperparams Comments  --------------------------------\n",
    "# - The max_depth hyperparameter controls the overall complexity of the tree. \n",
    "# This parameter is adequate under the assumption that a tree is built symmetrically. \n",
    "# However, there is no reason why a tree should be symmetrical. Indeed, optimal generalization \n",
    "# performance could be reached by growing some of the branches deeper than some others.\n",
    "\n",
    "# The hyperparameters min_samples_leaf, min_samples_split, \n",
    "# max_leaf_nodes, or min_impurity_decrease allow growing asymmetric trees and apply \n",
    "# a constraint at the leaves or nodes level. \n",
    "# ref. https://inria.github.io/scikit-learn-mooc/python_scripts/trees_hyperparameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-16 07:03:54,159] A new study created in memory with name: no-name-87ed987d-231a-4068-9484-e2e84c6a4dd9\n",
      "/tmp/ipykernel_1192939/1392542347.py:47: ExperimentalWarning: set_metric_names is experimental (supported from v3.2.0). The interface can change in the future.\n",
      "  study.set_metric_names([\"accuracy\"])\n",
      "[I 2024-10-16 07:03:54,296] Trial 0 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 18}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-16 07:03:54,319] Trial 1 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 14, 'min_samples_leaf': 17}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-16 07:03:54,351] Trial 7 finished with value: {'accuracy': 0.7865002541100828} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.7865534399413775.\n",
      "[I 2024-10-16 07:03:54,374] Trial 2 finished with value: {'accuracy': 0.8006063184767579} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,390] Trial 3 finished with value: {'accuracy': 0.768275242586486} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 5, 'min_samples_split': 28, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,420] Trial 6 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 11}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,455] Trial 8 finished with value: {'accuracy': 0.7752839532437448} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 9, 'min_samples_split': 30, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,483] Trial 9 finished with value: {'accuracy': 0.7682693330496755} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,514] Trial 4 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 29}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,526] Trial 11 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 21}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,545] Trial 12 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 12, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,572] Trial 5 finished with value: {'accuracy': 0.7556111052015743} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 21, 'min_samples_leaf': 26}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,620] Trial 10 finished with value: {'accuracy': 0.7809098322873455} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 26, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,633] Trial 14 finished with value: {'accuracy': 0.7738952120932762} and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 11, 'min_samples_leaf': 31}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,646] Trial 15 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 31}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,685] Trial 13 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 1, 'min_samples_split': 29, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,688] Trial 17 finished with value: {'accuracy': 0.7752957723173658} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 22, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,730] Trial 19 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 20, 'min_samples_leaf': 15}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,806] Trial 18 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 21, 'min_samples_leaf': 24}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,866] Trial 16 finished with value: {'accuracy': 0.7949804394331572} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,868] Trial 20 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 16, 'min_samples_leaf': 14}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,926] Trial 22 finished with value: {'accuracy': 0.768298880733728} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 14}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:54,964] Trial 24 finished with value: {'accuracy': 0.768298880733728} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 14}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,012] Trial 26 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,026] Trial 23 finished with value: {'accuracy': 0.768298880733728} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 13}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,032] Trial 21 finished with value: {'accuracy': 0.768298880733728} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 13}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,038] Trial 27 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,111] Trial 25 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,306] Trial 29 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,344] Trial 28 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,521] Trial 31 finished with value: {'accuracy': 0.7991821201054261} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,523] Trial 33 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,530] Trial 35 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,633] Trial 30 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,742] Trial 32 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,777] Trial 37 finished with value: {'accuracy': 0.7837109527355247} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,834] Trial 34 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,844] Trial 39 finished with value: {'accuracy': 0.7949981680435888} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,853] Trial 36 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,854] Trial 40 finished with value: {'accuracy': 0.7837109527355247} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,857] Trial 38 finished with value: {'accuracy': 0.7837109527355247} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,917] Trial 42 finished with value: {'accuracy': 0.7837109527355247} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,957] Trial 43 finished with value: {'accuracy': 0.7837109527355247} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:55,975] Trial 41 finished with value: {'accuracy': 0.7893368317791252} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:56,102] Trial 44 finished with value: {'accuracy': 0.7753016818541761} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:56,174] Trial 45 finished with value: {'accuracy': 0.7823044829746243} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:56,237] Trial 46 finished with value: {'accuracy': 0.7753016818541761} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:56,324] Trial 48 finished with value: {'accuracy': 0.7753016818541761} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:56,369] Trial 49 finished with value: {'accuracy': 0.7752957723173658} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:56,419] Trial 47 finished with value: {'accuracy': 0.7753016818541761} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:56,557] Trial 50 finished with value: {'accuracy': 0.7949804394331572} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.8006063184767579.\n",
      "[I 2024-10-16 07:03:56,624] Trial 57 finished with value: {'accuracy': 0.8047843610017846} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:56,643] Trial 56 finished with value: {'accuracy': 0.7949804394331572} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:56,662] Trial 53 finished with value: {'accuracy': 0.7949804394331572} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:56,666] Trial 55 finished with value: {'accuracy': 0.7949804394331572} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:56,681] Trial 52 finished with value: {'accuracy': 0.7949804394331572} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:56,693] Trial 51 finished with value: {'accuracy': 0.8047843610017846} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:56,717] Trial 54 finished with value: {'accuracy': 0.7949804394331572} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:56,820] Trial 59 finished with value: {'accuracy': 0.8047843610017846} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:56,834] Trial 58 finished with value: {'accuracy': 0.8047843610017846} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:56,904] Trial 60 finished with value: {'accuracy': 0.8005826803295157} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,059] Trial 61 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,164] Trial 64 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,210] Trial 63 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,268] Trial 62 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,330] Trial 65 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,422] Trial 66 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,487] Trial 72 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,538] Trial 67 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 14, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,649] Trial 70 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,675] Trial 75 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 14, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,685] Trial 69 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 18}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,749] Trial 68 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,758] Trial 73 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,765] Trial 71 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,804] Trial 74 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:57,904] Trial 76 finished with value: {'accuracy': 0.7696758028105757} and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,011] Trial 78 finished with value: {'accuracy': 0.7752957723173658} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,103] Trial 80 finished with value: {'accuracy': 0.7752957723173658} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,109] Trial 79 finished with value: {'accuracy': 0.7752957723173658} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 14, 'min_samples_leaf': 11}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,176] Trial 77 finished with value: {'accuracy': 0.7752957723173658} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 10}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,246] Trial 83 finished with value: {'accuracy': 0.7753016818541761} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 17}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,297] Trial 84 finished with value: {'accuracy': 0.7809039227505349} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 10}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,325] Trial 81 finished with value: {'accuracy': 0.7752957723173658} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 2, 'min_samples_split': 14, 'min_samples_leaf': 18}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,380] Trial 82 finished with value: {'accuracy': 0.7767022420782658} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 18}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,503] Trial 89 finished with value: {'accuracy': 0.7767140611518869} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,547] Trial 85 finished with value: {'accuracy': 0.7809157418241558} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,550] Trial 91 finished with value: {'accuracy': 0.7767199706886974} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,597] Trial 86 finished with value: {'accuracy': 0.7767140611518869} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,621] Trial 88 finished with value: {'accuracy': 0.7767140611518869} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,689] Trial 90 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,694] Trial 87 finished with value: {'accuracy': 0.7865534399413775} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,825] Trial 92 finished with value: {'accuracy': 0.7767199706886974} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,935] Trial 95 finished with value: {'accuracy': 0.7711177297923388} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,939] Trial 99 finished with value: {'accuracy': 0.7879244524814145} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,952] Trial 98 finished with value: {'accuracy': 0.7879244524814145} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:58,966] Trial 93 finished with value: {'accuracy': 0.7767140611518869} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:59,004] Trial 94 finished with value: {'accuracy': 0.7767140611518869} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:59,028] Trial 97 finished with value: {'accuracy': 0.787930362018225} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 32, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n",
      "[I 2024-10-16 07:03:59,037] Trial 96 finished with value: {'accuracy': 0.7879244524814145} and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.8047843610017846.\n"
     ]
    }
   ],
   "source": [
    "# --- TUNNING ---\n",
    "# --- Objective function: define the optimization metrics ---\n",
    "# (where, for what model, what metric)\n",
    "\n",
    "def objective(trial, x, y):\n",
    "\t\n",
    "\t\t\t\t# define search space\n",
    "\t\t\t\tparams = {\n",
    "\t\t\t\t\t\t\t\t'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "\t\t\t\t\t\t\t\t'splitter': trial.suggest_categorical('splitter', ['best', 'random']),\n",
    "\t\t\t\t\t\t\t\t'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "\t\t\t\t\t\t\t\t'min_samples_split': trial.suggest_int('min_samples_split', 2, 32),\n",
    "\t\t\t\t\t\t\t\t'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 32),\n",
    "\t\t\t\t\t\t\t\t'random_state': 0\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t\t# define model\n",
    "\t\t\t\tclf\t= DecisionTreeClassifier(**params)\n",
    "\n",
    "\t\t\t\t# Eval strategy\n",
    "\t\t\t\t# It gives me the list of k scores from cv\n",
    "\t\t\t\tcv_scores = cross_val_score(clf, x, y, cv=3, scoring='accuracy')\n",
    "\n",
    "\t\t\t\tobj = cv_scores.mean()\n",
    "\t\t\t\t\n",
    "\t\t\t\t# return score for each trial\n",
    "\t\t\t\treturn obj\n",
    "\n",
    "w_func = lambda trial: objective(trial, x=x_train, y=y_train) # just a wrapper\tto pass x and y\n",
    "\n",
    "# --- study: define searching strategy (How) ---\n",
    "\n",
    "# sampler=TPESampler(): Optuna uses the Tree-structured Parzen Estimator (TPE) \n",
    "# sampler, which is a Bayesian optimization method that efficiently searches \n",
    "# through the hyperparameter space.\n",
    "\n",
    "# pruner=MedianPruner(): Optuna can prune unpromising trials early, based on the median \n",
    "# value of intermediate results. This speeds up the optimization process by discarding \n",
    "# poor-performing hyperparameter combinations early.\n",
    "\n",
    "study=optuna.create_study(\n",
    "\tsampler= optuna.samplers.TPESampler(),\n",
    "\tpruner=optuna.pruners.MedianPruner(),\n",
    "\tdirection='maximize'\n",
    "\t)\n",
    "\n",
    "study.set_metric_names([\"accuracy\"])\n",
    "\n",
    "\n",
    "# -- Start optimizing ---\n",
    "study.optimize(\n",
    "\tfunc=w_func, \n",
    "\tn_trials=100,\n",
    "\ttimeout=None, # max time in seconds\n",
    "\tn_jobs=-1 # max job  in parallel. -1 = all cpus\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in artifacts/model_03/tunning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_params': {'criterion': 'entropy',\n",
       "  'splitter': 'best',\n",
       "  'max_depth': 3,\n",
       "  'min_samples_split': 10,\n",
       "  'min_samples_leaf': 8},\n",
       " 'best_value': 0.8047843610017846,\n",
       " 'metric_names': ['accuracy']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save tunning results\n",
    "utils.tunning_results(study, os.getenv(\"ARTIFACTS_PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: artifacts/model_03/model/model.pkl\n",
      "Timestamp: 2024-10-16 07:04:01\n"
     ]
    }
   ],
   "source": [
    "# --- TRAIN ---\n",
    "x_full = pd.concat([x_train, x_test])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "best_params = study.best_params\n",
    "clf = DecisionTreeClassifier(**best_params)\n",
    "model = clf.fit(x_full, y_full)\n",
    "\n",
    "# --- save as pickle ---\n",
    "artifact_path = os.path.join(os.getenv(\"ARTIFACTS_PATH\"), utils.get_nb_name(), 'model')\n",
    "os.makedirs(artifact_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(artifact_path, 'model.pkl'), 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"Model saved at: {os.path.join(artifact_path, 'model.pkl')}\")\n",
    "print(f'Timestamp: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
